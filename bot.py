import logging
import os
import sqlite3
import openai
import re
from difflib import get_close_matches
from fuzzywuzzy import fuzz, process
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters
)
import io
import tempfile
import json
import requests
from google.oauth2 import service_account
from google.cloud import vision

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
DB_FILE = "lab_data(2).db"
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=os.getenv("LOG_LEVEL", "INFO"),
)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ADMIN_TELEGRAM_ID = "5241327545"

openai.api_key = OPENAI_API_KEY
pending_requests = {}

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å–∏–Ω–æ–Ω–∏–º–æ–≤ —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö —Ä–∞—Å–∫–ª–∞–¥–æ–∫ –∏ –æ–ø–µ—á–∞—Ç–æ–∫
SYNONYMS = {
    r'\b—Ä—Ñ\b': '—Ä—Ñ-—Å—É–º–º–∞—Ä–Ω—ã–π',
    r'\b(ige?|–∏–≥–µ|ig[\s-]*e|–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω[\s-]*[–µe])\b': '–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω –µ',
    r'\b—Ä–µ–≤–º–æ—Ñ–∞–∫—Ç–æ—Ä\b': '—Ä—Ñ-—Å—É–º–º–∞—Ä–Ω—ã–π',
    r'\b–∞–ª—Ç\b': '–∞–ª–∞–Ω–∏–Ω–∞–º–∏–Ω–æ—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞ (–∞–ª—Ç)',
    r'\b–∞—Å—Ç\b': '–∞—Å–ø–∞—Ä—Ç–∞—Ç–∞–º–∏–Ω–æ—Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–∞–∑–∞ (–∞—Å—Ç)'
}

def apply_synonyms(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç —Å —É—á–µ—Ç–æ–º —Å–ª–æ–∂–Ω—ã—Ö —Å–∏–Ω–æ–Ω–∏–º–æ–≤."""
    text = text.lower().strip()
    # –ü—Ä–∏–º–µ—Ä –∑–∞–º–µ–Ω—ã –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –≤ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑–∞—Ö
    text = re.sub(r'(?i)immunoglobulin\s*e', '–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω –µ', text)
    text = re.sub(r'(?i)(ige|ig\s*e)', '–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω –µ', text)
    for pattern, replacement in SYNONYMS.items():
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    return text

def connect_to_db():
    try:
        return sqlite3.connect(DB_FILE)
    except sqlite3.Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ë–î: {e}")
        return None

def get_all_analyses():
    conn = connect_to_db()
    if not conn:
        return []
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT name, price, timeframe FROM analyses")
        data = cursor.fetchall()
        return [(normalize_text(name), price, timeframe) for name, price, timeframe in data]
    except sqlite3.Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return []
    finally:
        conn.close()

def get_competitor_data():
    conn = connect_to_db()
    if not conn:
        return []
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT name, lab, price, timeframe FROM competitor_prices")
        data = cursor.fetchall()
        return [(normalize_text(name), lab, price, timeframe) for name, lab, price, timeframe in data]
    except sqlite3.Error as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {e}")
        return []
    finally:
        conn.close()

def normalize_text(text):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
    text = text.lower().strip()
    text = re.sub(r'[^\w\s-]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text

def extract_matched_analyses(query, analyses):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤, —Å—Ä–∞–≤–Ω–∏–≤–∞—è —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∞–Ω–∞–ª–∏–∑–æ–≤.
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç fuzzywuzzy –¥–ª—è –Ω–µ—á–µ—Ç–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞.
    """
    matched = set()
    query = apply_synonyms(query)
    query_tokens = re.findall(r'\w+', query)
    analysis_names = [name for name, _, _ in analyses]
    
    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ä–µ–≥—É–ª—è—Ä–∫–µ
    for name in analysis_names:
        if re.search(r'\b' + re.escape(name) + r'\b', query, re.IGNORECASE):
            matched.add(name)
    
    # –ù–µ—á–µ—Ç–∫–∏–π –ø–æ–∏—Å–∫: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Å–º–æ—Ç—Ä–∏–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ —Å–ª–æ–≤–æ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
    for name in analysis_names:
        name_tokens = re.findall(r'\w+', name)
        for token in query_tokens:
            for n_token in name_tokens:
                if fuzz.partial_ratio(token, n_token) > 85:
                    matched.add(name)
                    break
            else:
                continue
            break

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤
    if re.search(r'\b—Ä—Ñ\b', query, re.IGNORECASE) and not any("—Ä—Ñ-—Å—É–º–º–∞—Ä–Ω—ã–π" in m for m in matched):
        matched.add("—Ä—Ñ-—Å—É–º–º–∞—Ä–Ω—ã–π")
    if re.search(r'\b(–∏–≥–µ|–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω)\b', query, re.IGNORECASE) and not any("–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω –µ" in m for m in matched):
        matched.add("–∏–º–º—É–Ω–æ–≥–ª–æ–±—É–ª–∏–Ω –µ")
    
    logger.info(f"–ù–∞–π–¥–µ–Ω—ã –∞–Ω–∞–ª–∏–∑—ã: {matched} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (—Ç–æ–∫–µ–Ω—ã): {query_tokens}")
    return ', '.join(matched) if matched else ''

def find_best_match(query, competitor_data):
    competitor_names = [name for name, _, _, _ in competitor_data]
    matches = get_close_matches(query, competitor_names, n=1, cutoff=0.5)
    if matches:
        for name, lab, price, timeframe in competitor_data:
            if name == matches[0]:
                return (name, lab, price, timeframe)
    return None

def compare_with_competitors(matched_names):
    competitor_data = get_competitor_data()
    if not matched_names:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."
    names = [name.strip() for name in matched_names.split(',')]
    results = []
    for name in names:
        best = find_best_match(name, competitor_data)
        if best:
            comp_name, lab, comp_price, comp_timeframe = best
            results.append(f"–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç ({lab}): {comp_name} ‚Äî {comp_price} KZT, –°—Ä–æ–∫: {comp_timeframe}")
        else:
            results.append(f"–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ '{name}' –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    return "\n".join(results)

async def notify_admin_about_missing_request(query, user_id, context):
    pending_requests[user_id] = query
    message = (f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}:\n\n"
               f"–ó–∞–ø—Ä–æ—Å: {query}\n\n"
               f"–î–ª—è –æ—Ç–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É: /reply {user_id} <–í–∞—à –æ—Ç–≤–µ—Ç>")
    try:
        await context.bot.send_message(chat_id=ADMIN_TELEGRAM_ID, text=message)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")

async def process_response(response, user_message, user_id, context):
    if any(phrase in response.lower() for phrase in ["–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç", "–Ω–µ—Ç –≤ –±–∞–∑–µ", "–Ω–µ –Ω–∞–π–¥–µ–Ω"]):
        await notify_admin_about_missing_request(user_message, user_id, context)
        return ("–ò–∑–≤–∏–Ω–∏—Ç–µ, —ç—Ç–æ—Ç –∞–Ω–∞–ª–∏–∑ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –Ω–∞—à–µ–π –±–∞–∑–µ. –ú—ã –ø–µ—Ä–µ–¥–∞–ª–∏ –∑–∞–ø—Ä–æ—Å –æ–ø–µ—Ä–∞—Ç–æ—Ä—É –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è. "
                "–í—ã –º–æ–∂–µ—Ç–µ –Ω–∞–ø—Ä—è–º—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É +77073145.")
    return response

def detect_text_from_image(image_path):
    try:
        credentials_json = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON")
        if not credentials_json:
            logger.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è GOOGLE_SERVICE_ACCOUNT_JSON –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
            return ""
        credentials_info = json.loads(credentials_json)
        credentials = service_account.Credentials.from_service_account_info(credentials_info)
        client = vision.ImageAnnotatorClient(credentials=credentials)
        with io.open(image_path, 'rb') as image_file:
            content = image_file.read()
        image = vision.Image(content=content)
        response = client.text_detection(image=image)
        if response.error.message:
            logger.error(f"Google Vision API error: {response.error.message}")
            return ""
        texts = response.text_annotations
        if texts:
            return texts[0].description
        return ""
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return ""

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –ü—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–æ—Ç–æ –±–æ—Ç –ø–µ—Ä–µ—Å—ã–ª–∞–µ—Ç –µ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É –≤–º–µ—Å—Ç–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–ª–∏–µ–Ω—Ç–µ,
    –∞ –∫–ª–∏–µ–Ω—Ç –ø–æ–ª—É—á–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä—É.
    """
    try:
        photo = update.message.photo[-1]
        file = await photo.get_file()
        user = update.message.from_user
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–µ: ID, username, –∫–æ–Ω—Ç–∞–∫—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –ø–æ–¥–ø–∏—Å–∏
        client_info = f"ID: {update.message.chat.id}\n"
        if user.username:
            client_info += f"Username: @{user.username}\n"
        client_info += f"–ò–º—è: {user.first_name} {user.last_name or ''}\n"
        if update.message.contact and update.message.contact.phone_number:
            client_info += f"–¢–µ–ª–µ—Ñ–æ–Ω: {update.message.contact.phone_number}\n"
        else:
            caption = update.message.caption or \"\"
            phone_match = re.search(r'(\\+7|8)[\\s-]?\\(?\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{2}[\\s-]?\\d{2}', caption)
            if phone_match:
                client_info += f"–¢–µ–ª–µ—Ñ–æ–Ω –∏–∑ –ø–æ–¥–ø–∏—Å–∏: {phone_match.group()}\n"
        
        caption_text = f"üì∑ –§–æ—Ç–æ –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞:\n{client_info}\n–î–ª—è –æ—Ç–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /reply {update.message.chat.id} <—Ç–µ–∫—Å—Ç>"
        await update.message.forward(chat_id=ADMIN_TELEGRAM_ID)
        await context.bot.send_message(chat_id=ADMIN_TELEGRAM_ID, text=caption_text)
        await update.message.reply_text("–í–∞—à –∑–∞–ø—Ä–æ—Å –ø–æ–ª—É—á–µ–Ω –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä—É –¥–ª—è —Ä—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏. –í—ã –º–æ–∂–µ—Ç–µ –Ω–∞–ø—Ä—è–º—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É +77073145.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å—ã–ª–∫–µ —Ñ–æ—Ç–æ: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:
    1. –°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
    2. –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –≤ OpenAI Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
    3. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å.
    """
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as tmp_file:
            temp_file_path = tmp_file.name
        await file.download_to_drive(custom_path=temp_file_path)
        with open(temp_file_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
        os.remove(temp_file_path)
        text = transcript.get("text", "")
        await update.message.reply_text(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        update.message.text = text
        await handle_message(update, context)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –Ø –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")

async def reply(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if str(update.message.chat.id) != ADMIN_TELEGRAM_ID:
        return
    try:
        parts = update.message.text.split(" ", 2)
        target_user = int(parts[1])
        operator_reply = parts[2]
        await context.bot.send_message(chat_id=target_user, text=operator_reply)
        await update.message.reply_text("–û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∫–ª–∏–µ–Ω—Ç—É.")
        pending_requests.pop(target_user, None)
    except (IndexError, ValueError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∫–æ–º–∞–Ω–¥–µ /reply: {e}")
        await update.message.reply_text("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /reply <user_id> <–æ—Ç–≤–µ—Ç>")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = normalize_text(update.message.text)
    user_id = update.message.chat.id
    logger.info(f"–ó–∞–ø—Ä–æ—Å –æ—Ç {user_id}: {user_message}")
    
    if "—Å—Ä–∞–≤–Ω–∏—Ç—å" in user_message:
        if user_id in pending_requests:
            saved_names = pending_requests[user_id]
            comp_response = compare_with_competitors(saved_names)
            if "–Ω–µ –Ω–∞–π–¥–µ–Ω–∞" in comp_response.lower():
                await notify_admin_about_missing_request(saved_names, user_id, context)
                comp_response += "\n\n–ò–∑–≤–∏–Ω–∏—Ç–µ, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –ó–∞–ø—Ä–æ—Å –ø–µ—Ä–µ–¥–∞–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä—É."
            await update.message.reply_text(comp_response)
            return
        else:
            await update.message.reply_text("–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.")
            return

    analyses = get_all_analyses()
    extracted_names = extract_matched_analyses(user_message, analyses)
    if extracted_names:
        pending_requests[user_id] = extracted_names
    else:
        pending_requests[user_id] = user_message

    response = ask_openai(user_message, analyses)
    final_response = await process_response(response, user_message, user_id, context)
    
    competitor_data = get_competitor_data()
    if competitor_data:
        final_response += "\n\n–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ü–µ–Ω—ã —Å –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞–º–∏, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ '—Å—Ä–∞–≤–Ω–∏—Ç—å'."
    
    await update.message.reply_text(final_response)

if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("reply", reply))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.CONTACT, handle_contact))  # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è handle_contact –Ω—É–∂–Ω–∞, –º–æ–∂–Ω–æ –µ—ë –¥–æ–±–∞–≤–∏—Ç—å
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω.")
    app.run_polling()
